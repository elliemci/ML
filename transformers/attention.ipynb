{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-spain",
   "metadata": {},
   "source": [
    "# Notebook Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-possibility",
   "metadata": {
    "id": "appreciated-bailey"
   },
   "source": [
    "1. Perform matrix multiplication with the use of Numpy's matrix multiplication.\n",
    "2. Compute weighted sum.\n",
    "3. Compute vectorized weight matrices.\n",
    "4. Use the softmax function from `scipy.special` to compute the attention scores.\n",
    "5. Utilize hstack from NumPy to concat the attention scores from multihead attention together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-pittsburgh",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-anime",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.random import randint\n",
    "from numpy import random\n",
    "from numpy import dot, matmul, hstack, vstack\n",
    "from scipy.special import softmax\n",
    "from math import sqrt\n",
    "\n",
    "#ignore warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "active-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-consequence",
   "metadata": {},
   "source": [
    "This Notebook is based on the following sources:\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "- [Transformers for Natural Language Processing](https://www.packtpub.com/product/transformers-for-natural-language-processing-second-edition/9781803247335), by Denis Rothman\n",
    "- [Machine Learning for Text](https://link.springer.com/book/10.1007/978-3-030-96623-2), by Charu C. Aggarwal\n",
    "- [Neural Networks and Deep Learning](https://link.springer.com/book/10.1007/978-3-319-94463-0), by Charu C. Aggarwal\n",
    "- https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-culture",
   "metadata": {},
   "source": [
    "We will discuss the inner workings of the network from the following paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-suggestion",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Link to the paper](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-equilibrium",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-repair",
   "metadata": {},
   "source": [
    "The neural architecture in a recurrent neural network (RNN) with  an extra attention layer added to.\n",
    "\n",
    "Image credit: [Neural Networks and Deep Learning](https://link.springer.com/book/10.1007/978-3-319-94463-0), by Charu C. Aggarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a339bb0",
   "metadata": {},
   "source": [
    "![Transformer Architecture](images/transformer_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84b1e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-whale",
   "metadata": {
    "id": "jewish-exhaust",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Positional Encoding\n",
    "<br>\n",
    "Different than RNN which  parse a sentence word by word in  a seequential maner, in transforme models each  word in   a  sentence simultaneously flows through. To account for the order of the words in the input sequence, the transformer adds a vector to each input embedding. These positional encoding vector values foollow a specific patteren and provide a way to compute a distances between embedding vectors once they are projected into Q/K/V and during the dot-prrooduct attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-foundation",
   "metadata": {
    "id": "dynamic-crawford",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The $PE(w_{t})$ is the positional encoding for the word $w$ at position $t$, which is a vector of dimension $d_{model}$ equal to the embedding dimension. We compute each dimension $i$ of this vector as follows: <br>\n",
    "\n",
    "$$\n",
    "PE_{i}\\left(w_{t}\\right)= \\begin{cases}\\sin \\left(k_{j} * t\\right) & \\text { if } \\quad i=2 j \\\\ \\cos \\left(k_{j} * t\\right) & \\text { if } \\quad i=2 j+1\\end{cases}\n",
    "$$\n",
    "where\n",
    "$$ w_k = \\frac{1}{{1000}^{\\frac{2k}{d}}} $$\n",
    "The frequencies are decreasing along the vector dimension and it forms geometric prrrogression from $2\\pi$ to $10000.2\\pi$. The positional embedding can be represented as a vector containing pairs of sin and  cos for each frequency:\n",
    "\n",
    "$$\n",
    "\\vec{p_t} = \\left[\\begin{array}{c}\n",
    "\\sin(w_1 \\cdot t) \\\\\n",
    "\\cos(w_1 \\cdot t) \\\\\n",
    "\\sin(w_2 \\cdot t) \\\\\n",
    "\\cos(w_2 \\cdot t) \\\\\n",
    "\\vdots \\\\\n",
    "\\sin(w_{\\frac{d}{2}} \\cdot t) \\\\\n",
    "\\cos(w_{\\frac{d}{2}} \\cdot t)\n",
    "\\end{array}\\right]_{d \\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-accessory",
   "metadata": {
    "id": "fifteen-boards",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can think of this as a bit representation of numbers with each dimension of the vector as a bit. Each bit changes periodically, and we can tell that one number is bigger than another because of the bits activated and their order. More of this intuition in this blog post <a href=\"https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\" target=\"_blank\">blog post</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-stylus",
   "metadata": {
    "id": "popular-advertising",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-silver",
   "metadata": {
    "id": "spiritual-justice",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For this simple example, the attention mechanism we are building, is scaled down to $d_{model} = 3$\n",
    "instead of $d_{model} = 512$. This brings the dimensions of the vector of an input $x$ down to\n",
    "$d_{model}$ = 3, which is simpler to visualize.\n",
    "\n",
    "Now, let's begin by defining the word embeddings of the four distinct words whose attention will be calculated. In practice, these word embeddings would have been created by an encoder; nevertheless, for the purposes of this example, we will manually define them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-washer",
   "metadata": {
    "id": "filled-found",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the sake of simplicity, we only use 4 inputs and 3 dim positional encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-hunger",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-artwork",
   "metadata": {
    "id": "automated-encyclopedia",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Inputs - Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunset-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1]\n",
      " [0 1 1]\n",
      " [1 0 0]\n",
      " [1 1 1]] \n",
      "\n",
      "\u001b[1;31mInputs:  4 \u001b[1;30m , \u001b[1;32mDimension:  3\n"
     ]
    }
   ],
   "source": [
    "# manually defined word embeddings\n",
    "word_1 = array([1, 0, 1])\n",
    "word_2 = array([0, 1, 1])\n",
    "word_3 = array([1, 0, 0])\n",
    "word_4 = array([1, 1, 1])\n",
    " \n",
    "# stacking the word embeddings into a single array\n",
    "words = array([word_1, word_2, word_3, word_4])\n",
    "\n",
    "# print stacked words\n",
    "print(words,'\\n')\n",
    "\n",
    "#print shape\n",
    "print('\\x1b[1;31mInputs: ',words.shape[0], '\\x1b[1;30m ,','\\x1b[1;32mDimension: ',words.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-million",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-tackle",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Weight Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b94ed",
   "metadata": {},
   "source": [
    "### Self Attention Calculation\n",
    "1. For each word create a Query vector, a Key vector, and a Value vector by multiplying the embedding vector of each word by the weight matrices ${W_Q}$, ${W_K}$ and ${W_V}$ that are learned during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49d53a",
   "metadata": {},
   "source": [
    "![Query, Key and Value vectors](images/transformer_self_attention_vectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-homeless",
   "metadata": {
    "id": "lyric-commissioner",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generating these weight matrices randomly;<br>\n",
    "<font color=red>Note: *In a neural network setting, these weights are usually small numbers, initialised randomly using an appropriate random distribution like for instance Gaussian distribution.* </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-trustee",
   "metadata": {},
   "source": [
    "In order to perform matrix multiplication, note that the number of rows in each of these matrices is equal to the dimension of the word embeddings (three in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pregnant-president",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# randomly create weight matrices\n",
    "W_Q = randint(3, size=(3, 3))\n",
    "W_K = randint(3, size=(3, 3))\n",
    "W_V = randint(3, size=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb29366",
   "metadata": {},
   "source": [
    "2.  Score each word of the input sentence against all the words in the sentence which determines how much focus to place on other parts of the input sentence as the word is encoded in ceratin position. The score is calculated by taking the dot product of the Query vector with key vector of the respective word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-matthew",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-monkey",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Matrix multiplication to obtain `Q,K,V`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-catch",
   "metadata": {},
   "source": [
    "This is a simple illustration of matrix multiplication, where $X$ are the words embedings, and $W^{Q}$, $W^{K}$ and $W^{V}$ the weight matrices and Q, K and V are abstractions used for computing attention.  The query, key, and value vectors for each word are generated by multiplying each word embedding by each of the weight matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-genetics",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Matrix Calculattion of Self Attention](images/self-attention-matrix-calculation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-azerbaijan",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Image sources: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-energy",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-executive",
   "metadata": {},
   "source": [
    "## Mattrix multiplication to find Queries, Keeys and Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-chrome",
   "metadata": {},
   "source": [
    "For every word embedding and every weight matrix $W_{Q}$, $W_{K}$ and $W_{V}$, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innocent-bowling",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generating the queries, keys and values separately for each input word embedding\n",
    "\n",
    "#generate weights for each word separetly - can be done with the numpy function dot(word, W) or \n",
    "#callingthe method doton the  array word passing the matrix W as argument query_1 = word_1.dot(W_Q)\n",
    "query_1 = dot(word_1, W_Q)\n",
    "key_1 = dot(word_1, W_K)\n",
    "value_1 = dot(word_1, W_V)\n",
    "\n",
    "# word 2\n",
    "query_2 = dot(word_2, W_Q)\n",
    "key_2 = dot(word_2, W_K) \n",
    "value_2 = dot(word_2, W_V)\n",
    "\n",
    "# word 3\n",
    "query_3 = dot(word_3, W_Q)\n",
    "key_3 = dot(word_3, W_K)\n",
    "value_3 = dot(word_3, W_V)\n",
    " \n",
    "# word 4    \n",
    "query_4 = dot(word_4, W_Q)\n",
    "key_4 = dot(word_4, W_K)\n",
    "value_4 = dot(word_4, W_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-reply",
   "metadata": {},
   "source": [
    "Addressing the first word only, compare the its query vector to all the key vectors using the dot product operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ruled-marina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 11 18 29]\n"
     ]
    }
   ],
   "source": [
    "# comparing the first query vector to all key vector\n",
    "scores = array([\n",
    "    dot(query_1, key_1),\n",
    "    dot(query_1, key_2),\n",
    "    dot(query_1, key_3),\n",
    "    dot(query_1, key_4)\n",
    "])\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-rabbit",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-definition",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4: Scaled Attention Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-finish",
   "metadata": {
    "id": "facial-proposal",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<br> <br>\n",
    "<font size = 4>\n",
    "The generalized attention is then computed by a weighted sum of the value vectors, where each value vector is paired with a corresponding key:\n",
    "    </font>\n",
    "The score determines how much focus to place on other parts of the input sentence as the word  is encoded at a certain position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-activation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d}}\\right) V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8ee71",
   "metadata": {},
   "source": [
    "3.  Divide the scores by the square root of the dimension of the key vectors, which  leads to having more stable gradients\n",
    "4. Pass the result thoughough a softmax operation, which determines how much each word will be expressed at this posisiton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0aa41c",
   "metadata": {},
   "source": [
    "![Self Attention calculation in matrix form](images/self-attention-matrix-calculation-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "secure-harbor",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.02989149e-02 2.96856554e-05 1.68937823e-03 9.67982021e-01]\n"
     ]
    }
   ],
   "source": [
    "# computing the weights using the softmax function\n",
    "weights = softmax(scores / sqrt(key_1.shape[0]))\n",
    "\n",
    "# we use Softmax that all sums up to 1\n",
    "# here we check if this is indeed the case\n",
    "assert(weights.sum().round(4) == 1.0)\n",
    "\n",
    "# print out result\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-chess",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-monkey",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 5: Weighted Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-rotation",
   "metadata": {},
   "source": [
    "**Compute the weighted sum.**\n",
    "\n",
    "The attention output is computed by weighting the total of the four value vectors, `value_1`, `value_2`,`value_3`, `value_4`. We can compute this by:\n",
    "- multiplying the `first row` of our weights matrix (from above) by `value_1` and then \n",
    "- `adding` this to \n",
    "- the multiplication of `second row` of our weights matrix with `value_2` and so on. \n",
    "\n",
    "**Note:** You can access the first row of a matrix with: `weights[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ef7d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [3.02989149e-02 2.96856554e-05 1.68937823e-03 9.67982021e-01]\n",
      "\n",
      "first row of the weight matrix: 0.03029891486600504\n",
      "values 1: [1 1 0]\n",
      "multiplication of first weigth by value_1: [0.03029891 0.03029891 0.        ]\n",
      "\n",
      "multiplication of second weigth by value_2: [0.00000000e+00 2.96856554e-05 2.96856554e-05]\n",
      "multiplication of third weigth by value_3: [0.00168938 0.00168938 0.        ]\n",
      "multiplication of forth weigth by value_4: [0.96798202 1.93596404 0.96798202]\n",
      "\n",
      "attention is the sum of the weighted values: [0.99997031 1.96798202 0.96801171]\n"
     ]
    }
   ],
   "source": [
    "print(f\"weights: {weights}\")\n",
    "print()\n",
    "print(f\"first row of the weight matrix: {weights[0]}\")\n",
    "print(f\"values 1: {value_1}\")\n",
    "print(f\"multiplication of first weigth by value_1: {weights[0] * value_1}\")\n",
    "print()\n",
    "print(f\"multiplication of second weigth by value_2: {weights[1] * value_2}\")\n",
    "print(f\"multiplication of third weigth by value_3: {weights[2] * value_3}\")\n",
    "print(f\"multiplication of forth weigth by value_4: {weights[3] * value_4}\")  \n",
    "print()\n",
    "print(f\"attention is the sum of the weighted values: {weights[0] * value_1 + weights[1] * value_2 + weights[2] * value_3 + weights[3] * value_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twenty-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99997031 1.96798202 0.96801171]\n"
     ]
    }
   ],
   "source": [
    "# weighted sum\n",
    "values = array([value_1, value_2, value_3, value_4])\n",
    "weights = array([weights[0], weights[1], weights[2], weights[3]])\n",
    "\n",
    "#attention = sum([weight * value for weight, value in zip(weights, values)])\n",
    "attention = dot(weights,values)\n",
    "\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-generic",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-stanford",
   "metadata": {},
   "source": [
    "# Vectorized Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-vancouver",
   "metadata": {},
   "source": [
    "As mentioned in the video \"What is the attention mechanism?\", for faster processing, the computations can be implemented in vectorized form to generate an attention output for all four words simultaneously. So, we are now looking at the vectorized version. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-principle",
   "metadata": {},
   "source": [
    "![Attention Computation Vectorized](images/attention_comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-conducting",
   "metadata": {},
   "source": [
    "For the vectorized version use the stack together words to get the matrices $Q$, $K$ and $V$, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "technological-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the weight matrices for queries Q, keys K and values V\n",
    "Q = dot(words, W_Q)\n",
    "K = dot(words, W_K)\n",
    "V = dot(words, W_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-belgium",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-burlington",
   "metadata": {},
   "source": [
    "Compute the attention by using this equation: $\\frac{Q K^{T}}{\\sqrt{d}}$ remember, `K.shape[1]` is our dimension here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-therapist",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d}}\\right) V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f532b",
   "metadata": {},
   "source": [
    "5. Multiply each value vector by the softmax score, which makes possible to focus on some words and less on others\n",
    "6. Sum up the weighted value vectors for that word\n",
    "\n",
    "The resulting vector is feeded-forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-homeless",
   "metadata": {},
   "source": [
    "Use the [softmax function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.softmax.html) from `scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "correct-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99997031 1.96798202 0.96801171]\n",
      " [0.99972362 1.89509373 0.89537011]\n",
      " [0.99307425 1.70208093 0.70900668]\n",
      " [0.99999705 1.9680079  0.96801085]]\n"
     ]
    }
   ],
   "source": [
    "# Specify the coolumn axis along which softmax sums up the values to 1\n",
    "attention = dot(softmax(dot(Q, K.T) / sqrt(K.shape[1]),  axis=1), V)\n",
    "\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-right",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-intelligence",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multihead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-donna",
   "metadata": {},
   "source": [
    "Different relations are captured by different attention mechanisims, thus Multi-Head Attentionn\n",
    "\n",
    "The weight matrices which are learned parameters within the neural architecture. These matrices emphasize certain dimensions (metaconcepts) of the words, and their impact is to highlight these metaconcepts. A single phrase may include many meta-concepts of interest. The purpose of the multihead technique is thus to use $k$ distinct sets of such matrices.\n",
    "\n",
    "Assume 3 outputs with 64 dimensions each, and these three outputs have learned weights.\n",
    "\n",
    "Hence, assume that three attention representations with a dimension of $d_{model} = 64$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broken-survivor",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.24774660e-01 3.99860972e-01 4.66656632e-02 9.73755519e-01\n",
      "  2.32771340e-01 9.06064345e-02 6.18386009e-01 3.82461991e-01\n",
      "  9.83230886e-01 4.66762893e-01 8.59940407e-01 6.80307539e-01\n",
      "  4.50499252e-01 1.32649612e-02 9.42201756e-01 5.63288218e-01\n",
      "  3.85416503e-01 1.59662522e-02 2.30893826e-01 2.41025466e-01\n",
      "  6.83263519e-01 6.09996658e-01 8.33194912e-01 1.73364654e-01\n",
      "  3.91060608e-01 1.82236088e-01 7.55361410e-01 4.25155874e-01\n",
      "  2.07941663e-01 5.67700328e-01 3.13132925e-02 8.42284775e-01\n",
      "  4.49754133e-01 3.95150236e-01 9.26658866e-01 7.27271996e-01\n",
      "  3.26540769e-01 5.70443974e-01 5.20834260e-01 9.61172024e-01\n",
      "  8.44533849e-01 7.47320110e-01 5.39692132e-01 5.86751166e-01\n",
      "  9.65255307e-01 6.07034248e-01 2.75999182e-01 2.96273506e-01\n",
      "  1.65266939e-01 1.56364067e-02 4.23401481e-01 3.94881518e-01\n",
      "  2.93488175e-01 1.40798227e-02 1.98842404e-01 7.11341953e-01\n",
      "  7.90175541e-01 6.05959975e-01 9.26300879e-01 6.51077026e-01\n",
      "  9.14959676e-01 8.50038578e-01 4.49450674e-01 9.54101165e-02]\n",
      " [3.70818252e-01 6.68841253e-01 6.65922357e-01 5.91297788e-01\n",
      "  2.74721793e-01 5.61243426e-01 3.82926875e-01 9.71712095e-01\n",
      "  8.48913824e-01 7.21729521e-01 2.35984920e-01 2.56068323e-01\n",
      "  4.04335895e-02 7.10662890e-01 1.10890821e-01 4.39336502e-01\n",
      "  2.01719202e-01 8.95763596e-01 4.75370223e-01 5.63275572e-01\n",
      "  6.95516086e-01 1.39331454e-01 6.04417379e-01 5.39841091e-01\n",
      "  2.03061225e-01 9.42853571e-01 5.98865466e-01 6.94784933e-01\n",
      "  8.80467839e-01 6.24354048e-01 2.95633686e-01 1.05494260e-01\n",
      "  4.56534570e-01 2.18440437e-01 4.16509948e-01 8.83280259e-01\n",
      "  3.24345021e-01 1.22087955e-01 3.56297838e-01 9.06828442e-01\n",
      "  2.72132249e-01 6.47690121e-01 5.20376995e-04 3.52568856e-01\n",
      "  3.04781258e-01 1.64655853e-01 5.34089419e-01 4.84829971e-01\n",
      "  6.92436033e-01 2.69412334e-01 2.44125522e-01 1.68291042e-01\n",
      "  2.18764220e-01 5.58102002e-01 4.03836171e-01 6.48922471e-02\n",
      "  2.53915414e-01 2.46876063e-01 6.96304273e-01 7.12270590e-01\n",
      "  1.48086930e-01 9.97740485e-01 2.66781014e-01 9.76614956e-01]\n",
      " [4.11037013e-01 3.30507329e-02 3.45071248e-01 6.34351345e-01\n",
      "  6.80705452e-01 5.30934583e-01 4.47783165e-01 5.52893089e-01\n",
      "  5.92696724e-01 8.08533263e-02 3.69654456e-01 2.42159938e-01\n",
      "  8.03139756e-01 4.70300634e-01 9.83423141e-01 3.98824442e-01\n",
      "  8.16431873e-01 7.98345125e-01 1.50717544e-01 5.08198777e-01\n",
      "  6.95812807e-01 8.58358805e-01 3.25958905e-01 2.20241048e-01\n",
      "  7.11149532e-01 8.09501046e-01 3.48665987e-01 9.61765511e-02\n",
      "  9.40523264e-01 3.97572021e-01 5.17751351e-01 8.37710106e-01\n",
      "  6.75690117e-01 7.35216119e-01 2.09071621e-01 5.41447974e-01\n",
      "  6.95784399e-01 2.28550022e-01 1.74954927e-01 9.82168343e-01\n",
      "  5.16635891e-01 2.60829175e-01 9.96253700e-01 9.65419351e-01\n",
      "  5.58293454e-01 8.82636343e-01 1.88707108e-01 2.78871353e-01\n",
      "  7.00357830e-01 8.46661142e-01 8.56324292e-01 4.04508127e-01\n",
      "  8.87770099e-01 8.50928449e-01 9.35634994e-01 7.85340651e-01\n",
      "  6.68988255e-01 5.80686621e-01 3.72282767e-01 9.40133442e-01\n",
      "  9.73663837e-01 2.83920975e-01 3.05363860e-01 4.85613754e-01]]\n"
     ]
    }
   ],
   "source": [
    "# just for attention head 1\n",
    "attention_head_1 = random.random((3, 64))\n",
    "print(attention_head_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-naples",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-elite",
   "metadata": {},
   "source": [
    "Suppose that the eight heads of the attention sub-layer have been trained. The transformer now has three output vectors, that is of the three input vectors that were either words or can be word fragments of $d_{model} = 64$ dimensions each:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-broad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Multi Head attention mechanism](images/transformer_multi-headed_self-attention-recap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-taxation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-anxiety",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "![Attention heads in multi-head attention mecchanism](images/transformer_self-attention_heads.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-oklahoma",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Image source: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "weird-burns",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one head (3, 64) dimension of 8 heads 512\n"
     ]
    }
   ],
   "source": [
    "z0 = random.random((3, 64))\n",
    "z1 = random.random((3, 64))\n",
    "z2 = random.random((3, 64))\n",
    "z3 = random.random((3, 64))\n",
    "z4 = random.random((3, 64))\n",
    "z5 = random.random((3, 64))\n",
    "z6 = random.random((3, 64))\n",
    "z7 = random.random((3, 64))\n",
    "print('Shape of one head', z0.shape, 'dimension of 8 heads', 64*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-lafayette",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Concatenation of heads 1 - 8 to obtain 8x64=512 output dimension of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-albert",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Concatenated atteention heads](images/transformer_attention_heads_weight_matrix_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-convergence",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Image source: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-spanking",
   "metadata": {},
   "source": [
    "Utilize [`hstack` from NumPy](https://numpy.org/doc/stable/reference/generated/numpy.hstack.html) to concat `z0 - z7` toghter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rocky-praise",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44842414 0.99445746 0.17592525 ... 0.37847642 0.36294427 0.99548049]\n",
      " [0.62789441 0.19427395 0.07094092 ... 0.95732289 0.57304143 0.93273074]\n",
      " [0.76336442 0.80691298 0.34630432 ... 0.13380374 0.41858062 0.79033774]]\n"
     ]
    }
   ],
   "source": [
    "output_attention = hstack((z0, z1, z2, z3, z4, z5, z6, z7))\n",
    "print(output_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-december",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-upset",
   "metadata": {},
   "source": [
    "# Additional: Feed-Forward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-asbestos",
   "metadata": {},
   "source": [
    "The illustration below depicts the fundamental structure of a feed-forward network, consisting of two hidden layers and one output layer. Even though each unit includes a single scalar variable, all units within a single layer are often represented as a single vector unit. Typically, vector units are shown as rectangles with connection matrices between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-marriage",
   "metadata": {},
   "source": [
    "![Feed-forward network structure](images/feed_forward_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-edgar",
   "metadata": {},
   "source": [
    "Image credit: [Neural Networks and Deep Learning](https://link.springer.com/book/10.1007/978-3-319-94463-0), by Charu C. Aggarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-insider",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-childhood",
   "metadata": {},
   "source": [
    "<font color=red size=3>To play with neural network use the website: [playground.tensorflow](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.97131&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "390.398px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
